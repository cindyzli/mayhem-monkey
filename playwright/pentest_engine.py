"""
Playwright-based pentesting engine for Mayhem Monkey.

Orchestrates automated security tests against a target URL using Playwright
for browser automation. Designed to be called by the Mayhem Monkey agent.

Usage:
    engine = PentestEngine()
    results = engine.run("https://target.example.com")
"""

from __future__ import annotations

import json
import re
import time
from dataclasses import asdict, dataclass, field
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional, Set
from urllib.parse import urlencode, urljoin, urlparse

from playwright.sync_api import (  # pip-installed playwright
    Browser,
    BrowserContext,
    Page,
    Response,
    sync_playwright,
)

from payloads import (  # sibling module in the same directory
    COMMON_CREDENTIALS,
    CSRF_TOKEN_NAMES,
    EXPECTED_SECURITY_HEADERS,
    FUZZ_PAYLOADS,
    OPEN_REDIRECT_PAYLOADS,
    PATH_TRAVERSAL_PAYLOADS,
    REDIRECT_PARAMS,
    SENSITIVE_PATHS,
    SQLI_PAYLOADS,
    XSS_CANARY,
    XSS_PAYLOADS,
)


@dataclass
class Finding:
    """A single security finding from a pentest check."""

    severity: str  # critical, high, medium, low, info
    category: str  # xss, sqli, headers, csrf, etc.
    title: str
    description: str
    url: str = ""
    evidence: str = ""
    timestamp: str = field(
        default_factory=lambda: datetime.now(timezone.utc).isoformat()
    )

    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class PentestEngine:
    """
    Automated pentesting engine using Playwright.

    Runs a configurable suite of security checks against a target URL
    and returns structured findings.
    """

    def __init__(self, headless: bool = True, timeout: int = 10000) -> None:
        self.headless = headless
        self.timeout = timeout
        self.findings: List[Finding] = []
        self._crawled_urls: Set[str] = set()
        self._forms: List[Dict[str, Any]] = []
        self._base_url: str = ""
        self._console_errors: List[str] = []

    def run(
        self,
        target_url: str,
        checks: Optional[List[str]] = None,
        max_crawl_depth: int = 2,
    ) -> Dict[str, Any]:
        """
        Run pentesting suite against target_url.

        Args:
            target_url: The URL to test.
            checks: List of check names to run. None = all checks.
            max_crawl_depth: How deep to crawl for discovering pages.

        Returns:
            Dict with findings, summary, and metadata.
        """
        self.findings = []
        self._crawled_urls = set()
        self._forms = []
        self._console_errors = []
        self._base_url = target_url

        all_checks = {
            "recon": self._check_recon,
            "security_headers": self._check_security_headers,
            "cookie_security": self._check_cookie_security,
            "xss": self._check_xss,
            "sqli": self._check_sqli,
            "csrf": self._check_csrf,
            "open_redirect": self._check_open_redirect,
            "sensitive_paths": self._check_sensitive_paths,
            "clickjacking": self._check_clickjacking,
            "form_security": self._check_form_security,
            "input_fuzzing": self._check_input_fuzzing,
            "mixed_content": self._check_mixed_content,
            "info_disclosure": self._check_info_disclosure,
            "auth_testing": self._check_auth_testing,
            "cors": self._check_cors,
            "subdomain_takeover": self._check_subdomain_takeover,
        }

        selected = checks or list(all_checks.keys())

        with sync_playwright() as pw:
            browser = pw.chromium.launch(headless=self.headless)
            context = browser.new_context(
                ignore_https_errors=True,
                user_agent=(
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/120.0.0.0 Safari/537.36"
                ),
            )
            context.set_default_timeout(self.timeout)
            page = context.new_page()

            # Capture console errors
            page.on("console", self._on_console_message)

            # Navigate to target
            try:
                resp = page.goto(target_url, wait_until="domcontentloaded")
            except Exception as exc:
                self._add_finding(
                    "critical", "connectivity", "Target unreachable",
                    f"Could not connect to {target_url}: {exc}",
                    url=target_url,
                )
                browser.close()
                return self._build_report(target_url)

            # Run initial recon to discover pages and forms
            if "recon" in selected:
                self._check_recon(page, context, target_url, max_crawl_depth)
                selected = [c for c in selected if c != "recon"]

            # Run each selected check
            for check_name in selected:
                if check_name in all_checks:
                    try:
                        all_checks[check_name](page, context, target_url)
                    except Exception as exc:
                        self._add_finding(
                            "info", "engine", f"Check {check_name} failed",
                            str(exc), url=target_url,
                        )

            browser.close()

        return self._build_report(target_url)

    # ------------------------------------------------------------------
    # Recon & crawling
    # ------------------------------------------------------------------
    def _check_recon(
        self,
        page: Page,
        context: BrowserContext,
        target_url: str,
        max_depth: int = 2,
    ) -> None:
        """Crawl the target to discover pages, forms, and inputs."""
        self._crawl(page, target_url, depth=0, max_depth=max_depth)
        self._add_finding(
            "info", "recon", "Crawl complete",
            f"Discovered {len(self._crawled_urls)} URLs and {len(self._forms)} forms",
            url=target_url,
        )

    def _crawl(self, page: Page, url: str, depth: int, max_depth: int) -> None:
        if depth > max_depth or url in self._crawled_urls:
            return
        if not self._is_same_origin(url):
            return

        self._crawled_urls.add(url)
        try:
            page.goto(url, wait_until="domcontentloaded")
        except Exception:
            return

        # Extract forms
        forms = page.evaluate("""() => {
            return Array.from(document.querySelectorAll('form')).map(form => ({
                action: form.action,
                method: (form.method || 'GET').toUpperCase(),
                inputs: Array.from(form.querySelectorAll('input, textarea, select')).map(el => ({
                    name: el.name || '',
                    type: el.type || 'text',
                    tag: el.tagName.toLowerCase(),
                    value: el.value || '',
                    id: el.id || '',
                }))
            }));
        }""")
        for form in forms:
            form["page_url"] = url
            self._forms.append(form)

        # Extract links for further crawling
        links = page.evaluate("""() => {
            return Array.from(document.querySelectorAll('a[href]'))
                .map(a => a.href)
                .filter(href => href.startsWith('http'));
        }""")

        for link in links:
            if self._is_same_origin(link) and link not in self._crawled_urls:
                self._crawl(page, link, depth + 1, max_depth)
                # Navigate back to continue
                try:
                    page.goto(url, wait_until="domcontentloaded")
                except Exception:
                    return

    # ------------------------------------------------------------------
    # Security headers
    # ------------------------------------------------------------------
    def _check_security_headers(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Check for missing or misconfigured security headers."""
        resp = page.goto(target_url, wait_until="domcontentloaded")
        if not resp:
            return

        headers = resp.headers
        for header_name, description in EXPECTED_SECURITY_HEADERS.items():
            if header_name not in headers:
                severity = "medium"
                if header_name in (
                    "strict-transport-security",
                    "content-security-policy",
                ):
                    severity = "high"
                self._add_finding(
                    severity, "headers",
                    f"Missing {header_name} header",
                    description,
                    url=target_url,
                    evidence=f"Header '{header_name}' not found in response",
                )

        # Check for overly permissive CSP
        csp = headers.get("content-security-policy", "")
        if csp:
            if "unsafe-inline" in csp:
                self._add_finding(
                    "medium", "headers",
                    "CSP allows unsafe-inline",
                    "Content-Security-Policy contains 'unsafe-inline' which weakens XSS protection",
                    url=target_url, evidence=f"CSP: {csp[:200]}",
                )
            if "unsafe-eval" in csp:
                self._add_finding(
                    "medium", "headers",
                    "CSP allows unsafe-eval",
                    "Content-Security-Policy contains 'unsafe-eval' which allows eval()",
                    url=target_url, evidence=f"CSP: {csp[:200]}",
                )
            if "*" in csp.split():
                self._add_finding(
                    "high", "headers",
                    "CSP allows wildcard sources",
                    "Content-Security-Policy contains '*' wildcard source directive",
                    url=target_url, evidence=f"CSP: {csp[:200]}",
                )

        # Check server header info leak
        server = headers.get("server", "")
        if server and any(v in server.lower() for v in ["apache/", "nginx/", "iis/"]):
            self._add_finding(
                "low", "headers",
                "Server version disclosed",
                f"Server header reveals software version: {server}",
                url=target_url, evidence=f"Server: {server}",
            )

        x_powered = headers.get("x-powered-by", "")
        if x_powered:
            self._add_finding(
                "low", "headers",
                "X-Powered-By header present",
                f"Technology stack disclosed: {x_powered}",
                url=target_url, evidence=f"X-Powered-By: {x_powered}",
            )

    # ------------------------------------------------------------------
    # Cookie security
    # ------------------------------------------------------------------
    def _check_cookie_security(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Analyze cookies for security flags."""
        page.goto(target_url, wait_until="domcontentloaded")
        cookies = context.cookies()
        for cookie in cookies:
            name = cookie.get("name", "unknown")
            issues = []
            if not cookie.get("secure", False):
                issues.append("missing Secure flag")
            if not cookie.get("httpOnly", False):
                issues.append("missing HttpOnly flag")
            same_site = cookie.get("sameSite", "None")
            if same_site == "None" or not same_site:
                issues.append("SameSite=None or missing")

            if issues:
                severity = "medium"
                # Session cookies missing security flags are higher severity
                if any(
                    kw in name.lower()
                    for kw in ["session", "token", "auth", "jwt", "sid"]
                ):
                    severity = "high"
                self._add_finding(
                    severity, "cookies",
                    f"Insecure cookie: {name}",
                    f"Cookie '{name}' has: {', '.join(issues)}",
                    url=target_url,
                    evidence=f"Cookie: {name}, Domain: {cookie.get('domain', '')}",
                )

    # ------------------------------------------------------------------
    # XSS testing
    # ------------------------------------------------------------------
    def _check_xss(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Test for reflected XSS in URL parameters and form inputs."""
        # Test reflected XSS via URL parameters
        self._test_reflected_xss_params(page, target_url)

        # Test XSS in form inputs
        self._test_xss_in_forms(page, context, target_url)

        # Test DOM-based XSS sinks
        self._test_dom_xss_sinks(page, target_url)

    def _test_reflected_xss_params(self, page: Page, target_url: str) -> None:
        """Inject XSS canary into URL parameters and check for reflection."""
        parsed = urlparse(target_url)
        if not parsed.query:
            # Try common parameter names
            test_params = ["q", "search", "query", "id", "name", "page", "url", "input"]
        else:
            test_params = [p.split("=")[0] for p in parsed.query.split("&")]

        for param in test_params[:5]:
            # First test with canary to see if input is reflected
            canary_url = self._inject_param(target_url, param, XSS_CANARY)
            try:
                page.goto(canary_url, wait_until="domcontentloaded")
                body = page.content()
                if XSS_CANARY in body:
                    # Input is reflected â€” now test with actual payloads
                    for payload in XSS_PAYLOADS[:8]:
                        test_url = self._inject_param(target_url, param, payload)
                        try:
                            page.goto(test_url, wait_until="domcontentloaded")
                            content = page.content()
                            # Check if payload appears unescaped
                            if payload in content and "<script>" not in self._html_escaped(payload):
                                self._add_finding(
                                    "critical", "xss",
                                    f"Reflected XSS via parameter '{param}'",
                                    f"Payload reflected unescaped in response body",
                                    url=test_url,
                                    evidence=f"Payload: {payload[:100]}",
                                )
                                break
                        except Exception:
                            continue
            except Exception:
                continue

    def _test_xss_in_forms(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Submit XSS payloads through discovered forms."""
        for form in self._forms[:5]:
            try:
                page.goto(form["page_url"], wait_until="domcontentloaded")
            except Exception:
                continue

            text_inputs = [
                inp for inp in form["inputs"]
                if inp["type"] in ("text", "search", "url", "email", "tel", "")
                and inp["name"]
            ]
            if not text_inputs:
                continue

            # Test a subset of XSS payloads
            for payload in XSS_PAYLOADS[:5]:
                try:
                    page.goto(form["page_url"], wait_until="domcontentloaded")
                    for inp in text_inputs:
                        selector = f'[name="{inp["name"]}"]'
                        el = page.query_selector(selector)
                        if el:
                            el.fill(payload)

                    # Submit the form
                    form_el = page.query_selector("form")
                    if form_el:
                        submit_btn = form_el.query_selector(
                            'button[type="submit"], input[type="submit"]'
                        )
                        if submit_btn:
                            submit_btn.click()
                        else:
                            form_el.evaluate("form => form.submit()")

                        page.wait_for_load_state("domcontentloaded")
                        content = page.content()
                        if payload in content:
                            self._add_finding(
                                "critical", "xss",
                                f"Stored/reflected XSS via form at {form['page_url']}",
                                f"XSS payload submitted through form input '{text_inputs[0]['name']}' appears in response",
                                url=form["page_url"],
                                evidence=f"Payload: {payload[:100]}",
                            )
                            break
                except Exception:
                    continue

    def _test_dom_xss_sinks(self, page: Page, target_url: str) -> None:
        """Detect dangerous DOM XSS sinks in page JavaScript."""
        page.goto(target_url, wait_until="domcontentloaded")
        sinks = page.evaluate("""() => {
            const scripts = Array.from(document.querySelectorAll('script'));
            const sinks = [];
            const patterns = [
                'document.write', 'document.writeln', '.innerHTML',
                'eval(', 'setTimeout(', 'setInterval(',
                '.outerHTML', 'document.location', 'window.location',
                '.insertAdjacentHTML', 'document.domain',
            ];
            for (const script of scripts) {
                const src = script.textContent || '';
                for (const pattern of patterns) {
                    if (src.includes(pattern)) {
                        const idx = src.indexOf(pattern);
                        const context = src.substring(
                            Math.max(0, idx - 30), idx + pattern.length + 30
                        ).trim();
                        sinks.push({ pattern, context });
                    }
                }
            }
            return sinks;
        }""")

        if sinks:
            unique_patterns = set(s["pattern"] for s in sinks)
            self._add_finding(
                "medium", "xss",
                "Potential DOM XSS sinks detected",
                f"Found {len(sinks)} potential DOM XSS sinks: {', '.join(unique_patterns)}",
                url=target_url,
                evidence=json.dumps(sinks[:5], indent=2),
            )

    # ------------------------------------------------------------------
    # SQL injection testing
    # ------------------------------------------------------------------
    def _check_sqli(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Test for SQL injection in URL parameters and form inputs."""
        self._test_sqli_params(page, target_url)
        self._test_sqli_forms(page, target_url)

    def _test_sqli_params(self, page: Page, target_url: str) -> None:
        """Test URL parameters for SQL injection indicators."""
        parsed = urlparse(target_url)
        if not parsed.query:
            test_params = ["id", "page", "cat", "item", "user", "product"]
        else:
            test_params = [p.split("=")[0] for p in parsed.query.split("&")]

        sql_error_patterns = [
            r"sql syntax",
            r"mysql_fetch",
            r"ORA-\d{5}",
            r"microsoft.*odbc",
            r"postgresql.*error",
            r"sqlite.*error",
            r"syntax error.*sql",
            r"unclosed quotation mark",
            r"pg_query\(\)",
            r"you have an error in your sql",
            r"warning.*mysql",
            r"valid mysql result",
            r"supplied argument is not a valid",
        ]

        for param in test_params[:3]:
            # Get baseline response
            baseline_url = self._inject_param(target_url, param, "1")
            try:
                page.goto(baseline_url, wait_until="domcontentloaded")
                baseline_content = page.content()
                baseline_len = len(baseline_content)
            except Exception:
                continue

            for payload in SQLI_PAYLOADS[:8]:
                test_url = self._inject_param(target_url, param, payload)
                try:
                    start = time.time()
                    page.goto(test_url, wait_until="domcontentloaded")
                    elapsed = time.time() - start
                    content = page.content()

                    # Check for SQL error messages
                    for pattern in sql_error_patterns:
                        match = re.search(pattern, content, re.IGNORECASE)
                        if match and not re.search(pattern, baseline_content, re.IGNORECASE):
                            self._add_finding(
                                "critical", "sqli",
                                f"SQL injection error in parameter '{param}'",
                                f"SQL error message triggered by injection payload",
                                url=test_url,
                                evidence=f"Payload: {payload}, Error: {match.group(0)}",
                            )
                            return

                    # Check for time-based blind SQLi
                    if "SLEEP" in payload or "WAITFOR" in payload or "pg_sleep" in payload:
                        if elapsed > 2.5:
                            self._add_finding(
                                "high", "sqli",
                                f"Possible blind SQL injection in parameter '{param}'",
                                f"Time-based payload caused {elapsed:.1f}s delay (expected ~3s)",
                                url=test_url,
                                evidence=f"Payload: {payload}, Delay: {elapsed:.1f}s",
                            )
                            return

                    # Check for boolean-based differences
                    if payload in ("' AND 1=1--", "' AND 1=2--"):
                        diff = abs(len(content) - baseline_len)
                        if diff > 100:
                            self._add_finding(
                                "medium", "sqli",
                                f"Possible boolean-based SQL injection in '{param}'",
                                f"Response length differs by {diff} bytes with boolean payload",
                                url=test_url,
                                evidence=f"Payload: {payload}, Baseline: {baseline_len}, Response: {len(content)}",
                            )

                except Exception:
                    continue

    def _test_sqli_forms(self, page: Page, target_url: str) -> None:
        """Test form inputs for SQL injection."""
        sql_error_patterns = [
            r"sql syntax", r"mysql_fetch", r"ORA-\d{5}",
            r"postgresql.*error", r"sqlite.*error",
            r"you have an error in your sql",
        ]

        for form in self._forms[:3]:
            text_inputs = [
                inp for inp in form["inputs"]
                if inp["type"] in ("text", "search", "password", "email", "hidden", "")
                and inp["name"]
            ]
            if not text_inputs:
                continue

            for payload in SQLI_PAYLOADS[:5]:
                try:
                    page.goto(form["page_url"], wait_until="domcontentloaded")
                    for inp in text_inputs:
                        el = page.query_selector(f'[name="{inp["name"]}"]')
                        if el:
                            el.fill(payload)

                    form_el = page.query_selector("form")
                    if form_el:
                        submit_btn = form_el.query_selector(
                            'button[type="submit"], input[type="submit"]'
                        )
                        if submit_btn:
                            submit_btn.click()
                        else:
                            form_el.evaluate("form => form.submit()")

                        page.wait_for_load_state("domcontentloaded")
                        content = page.content()
                        for pattern in sql_error_patterns:
                            if re.search(pattern, content, re.IGNORECASE):
                                self._add_finding(
                                    "critical", "sqli",
                                    f"SQL injection via form at {form['page_url']}",
                                    f"SQL error message triggered through form input",
                                    url=form["page_url"],
                                    evidence=f"Payload: {payload}, Input: {text_inputs[0]['name']}",
                                )
                                return
                except Exception:
                    continue

    # ------------------------------------------------------------------
    # CSRF detection
    # ------------------------------------------------------------------
    def _check_csrf(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Check forms for CSRF protection tokens."""
        for form in self._forms:
            if form["method"] != "POST":
                continue

            has_csrf_token = False
            for inp in form["inputs"]:
                if inp["type"] == "hidden" and any(
                    tok in inp["name"].lower() for tok in CSRF_TOKEN_NAMES
                ):
                    has_csrf_token = True
                    break

            if not has_csrf_token:
                self._add_finding(
                    "high", "csrf",
                    f"Missing CSRF token in POST form",
                    f"POST form at {form['page_url']} (action: {form['action']}) "
                    f"has no CSRF token in hidden inputs",
                    url=form["page_url"],
                    evidence=f"Form action: {form['action']}, Method: POST",
                )

    # ------------------------------------------------------------------
    # Open redirect testing
    # ------------------------------------------------------------------
    def _check_open_redirect(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Test for open redirect vulnerabilities."""
        for param in REDIRECT_PARAMS[:8]:
            for payload in OPEN_REDIRECT_PAYLOADS[:4]:
                test_url = self._inject_param(target_url, param, payload)
                try:
                    resp = page.goto(test_url, wait_until="domcontentloaded")
                    final_url = page.url
                    if "evil.com" in final_url:
                        self._add_finding(
                            "high", "open_redirect",
                            f"Open redirect via parameter '{param}'",
                            f"Application redirected to external domain",
                            url=test_url,
                            evidence=f"Payload: {payload}, Redirected to: {final_url}",
                        )
                        return
                except Exception:
                    continue

    # ------------------------------------------------------------------
    # Sensitive path probing
    # ------------------------------------------------------------------
    def _check_sensitive_paths(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Probe for sensitive files and paths."""
        parsed = urlparse(target_url)
        base = f"{parsed.scheme}://{parsed.netloc}"

        for path in SENSITIVE_PATHS:
            probe_url = base + path
            try:
                resp = page.goto(probe_url, wait_until="domcontentloaded")
                if resp and resp.status == 200:
                    content = page.content()
                    content_len = len(content)

                    # Skip generic 200 pages (soft 404s) by checking content
                    if content_len < 100:
                        continue

                    severity = "medium"
                    if any(
                        s in path
                        for s in [".env", ".git", "config", "phpinfo", "actuator/env"]
                    ):
                        severity = "high"
                    if path in ("/.env", "/.git/config"):
                        severity = "critical"

                    self._add_finding(
                        severity, "info_disclosure",
                        f"Sensitive path accessible: {path}",
                        f"Path {path} returned HTTP 200 with {content_len} bytes",
                        url=probe_url,
                        evidence=f"Status: {resp.status}, Length: {content_len}",
                    )
            except Exception:
                continue

    # ------------------------------------------------------------------
    # Clickjacking
    # ------------------------------------------------------------------
    def _check_clickjacking(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Test if the target can be framed (clickjacking)."""
        resp = page.goto(target_url, wait_until="domcontentloaded")
        if not resp:
            return

        headers = resp.headers
        x_frame = headers.get("x-frame-options", "").lower()
        csp = headers.get("content-security-policy", "").lower()

        has_frame_protection = False
        if x_frame in ("deny", "sameorigin"):
            has_frame_protection = True
        if "frame-ancestors" in csp:
            has_frame_protection = True

        if not has_frame_protection:
            # Verify by actually trying to frame it
            test_html = f"""
            <html><body>
            <iframe src="{target_url}" width="500" height="500"></iframe>
            </body></html>
            """
            page.set_content(test_html)
            iframe = page.query_selector("iframe")
            if iframe:
                self._add_finding(
                    "medium", "clickjacking",
                    "Page is frameable (clickjacking risk)",
                    "No X-Frame-Options or CSP frame-ancestors directive found. "
                    "Page can be embedded in an iframe on an attacker's site.",
                    url=target_url,
                    evidence="Missing X-Frame-Options and CSP frame-ancestors",
                )

    # ------------------------------------------------------------------
    # Form security analysis
    # ------------------------------------------------------------------
    def _check_form_security(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Analyze forms for security issues."""
        for form in self._forms:
            # Check for password fields sent over GET
            has_password = any(
                inp["type"] == "password" for inp in form["inputs"]
            )
            if has_password and form["method"] == "GET":
                self._add_finding(
                    "high", "form_security",
                    "Password sent via GET request",
                    f"Form at {form['page_url']} submits password field via GET method. "
                    f"Credentials will appear in URL, browser history, and server logs.",
                    url=form["page_url"],
                    evidence=f"Form action: {form['action']}, Method: GET",
                )

            # Check for autocomplete on password fields
            if has_password:
                try:
                    page.goto(form["page_url"], wait_until="domcontentloaded")
                    pw_field = page.query_selector('input[type="password"]')
                    if pw_field:
                        autocomplete = pw_field.get_attribute("autocomplete")
                        if autocomplete != "off" and autocomplete != "new-password":
                            self._add_finding(
                                "low", "form_security",
                                "Password autocomplete enabled",
                                f"Password field does not disable autocomplete",
                                url=form["page_url"],
                            )
                except Exception:
                    pass

            # Check for forms submitting to HTTP from HTTPS
            if form["action"].startswith("http://") and target_url.startswith("https://"):
                self._add_finding(
                    "high", "form_security",
                    "Form submits to HTTP from HTTPS page",
                    f"Form submits data to insecure HTTP endpoint: {form['action']}",
                    url=form["page_url"],
                    evidence=f"Action: {form['action']}",
                )

    # ------------------------------------------------------------------
    # Input fuzzing
    # ------------------------------------------------------------------
    def _check_input_fuzzing(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Fuzz form inputs with edge-case values to find crashes."""
        for form in self._forms[:3]:
            text_inputs = [
                inp for inp in form["inputs"]
                if inp["type"] in ("text", "search", "email", "tel", "url", "")
                and inp["name"]
            ]
            if not text_inputs:
                continue

            for payload in FUZZ_PAYLOADS[:10]:
                try:
                    page.goto(form["page_url"], wait_until="domcontentloaded")
                    for inp in text_inputs:
                        el = page.query_selector(f'[name="{inp["name"]}"]')
                        if el:
                            el.fill(str(payload))

                    form_el = page.query_selector("form")
                    if form_el:
                        submit_btn = form_el.query_selector(
                            'button[type="submit"], input[type="submit"]'
                        )
                        if submit_btn:
                            submit_btn.click()
                        else:
                            form_el.evaluate("form => form.submit()")

                        page.wait_for_load_state("domcontentloaded")

                        # Check for 500 errors
                        resp_text = page.content()
                        if any(
                            err in resp_text.lower()
                            for err in [
                                "internal server error",
                                "500 error",
                                "traceback",
                                "stack trace",
                                "exception",
                                "fatal error",
                            ]
                        ):
                            self._add_finding(
                                "high", "input_fuzzing",
                                f"Server error triggered by fuzz input",
                                f"Payload '{str(payload)[:50]}' caused server error at {form['page_url']}",
                                url=form["page_url"],
                                evidence=f"Input: {text_inputs[0]['name']}, Payload: {str(payload)[:80]}",
                            )
                except Exception:
                    continue

    # ------------------------------------------------------------------
    # Mixed content detection
    # ------------------------------------------------------------------
    def _check_mixed_content(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Detect mixed HTTP/HTTPS content on HTTPS pages."""
        if not target_url.startswith("https://"):
            return

        for url in list(self._crawled_urls)[:10]:
            if not url.startswith("https://"):
                continue
            try:
                page.goto(url, wait_until="domcontentloaded")
                mixed = page.evaluate("""() => {
                    const resources = [];
                    document.querySelectorAll('img[src], script[src], link[href], iframe[src], video[src], audio[src], source[src]').forEach(el => {
                        const src = el.src || el.href || '';
                        if (src.startsWith('http://')) {
                            resources.push({ tag: el.tagName, src: src.substring(0, 100) });
                        }
                    });
                    return resources;
                }""")
                if mixed:
                    self._add_finding(
                        "medium", "mixed_content",
                        f"Mixed content on HTTPS page",
                        f"Found {len(mixed)} HTTP resources loaded on HTTPS page",
                        url=url,
                        evidence=json.dumps(mixed[:5]),
                    )
            except Exception:
                continue

    # ------------------------------------------------------------------
    # Information disclosure
    # ------------------------------------------------------------------
    def _check_info_disclosure(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Check for information disclosure in HTML comments, errors, etc."""
        for url in list(self._crawled_urls)[:5]:
            try:
                page.goto(url, wait_until="domcontentloaded")
                content = page.content()

                # Check HTML comments for sensitive info
                comments = re.findall(r"<!--(.*?)-->", content, re.DOTALL)
                sensitive_comment_patterns = [
                    r"password", r"secret", r"api[_-]?key", r"token",
                    r"TODO", r"FIXME", r"HACK", r"BUG",
                    r"username", r"admin", r"debug",
                ]
                for comment in comments:
                    for pattern in sensitive_comment_patterns:
                        if re.search(pattern, comment, re.IGNORECASE):
                            self._add_finding(
                                "low", "info_disclosure",
                                f"Sensitive HTML comment found",
                                f"HTML comment contains potentially sensitive keyword: {pattern}",
                                url=url,
                                evidence=f"Comment: {comment[:150].strip()}",
                            )
                            break

                # Check for stack traces or debug info
                debug_patterns = [
                    (r"Traceback \(most recent call last\)", "Python stack trace"),
                    (r"at .+\.java:\d+", "Java stack trace"),
                    (r"at .+\.(js|ts):\d+:\d+", "JavaScript stack trace"),
                    (r"Fatal error:.+on line \d+", "PHP fatal error"),
                    (r"DEBUG\s*=\s*True", "Debug mode enabled"),
                ]
                for pattern, desc in debug_patterns:
                    if re.search(pattern, content):
                        self._add_finding(
                            "medium", "info_disclosure",
                            f"Debug information exposed: {desc}",
                            f"Page contains {desc}",
                            url=url,
                            evidence=re.search(pattern, content).group(0)[:150],
                        )

            except Exception:
                continue

    # ------------------------------------------------------------------
    # Authentication testing
    # ------------------------------------------------------------------
    def _check_auth_testing(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Test authentication forms for common weaknesses."""
        login_forms = [
            f for f in self._forms
            if any(inp["type"] == "password" for inp in f["inputs"])
        ]

        for form in login_forms[:2]:
            try:
                # Test for default credentials
                username_input = next(
                    (inp for inp in form["inputs"]
                     if inp["type"] in ("text", "email", "") and inp["name"]),
                    None,
                )
                password_input = next(
                    (inp for inp in form["inputs"]
                     if inp["type"] == "password" and inp["name"]),
                    None,
                )

                if not username_input or not password_input:
                    continue

                # Check login error message consistency (user enumeration)
                page.goto(form["page_url"], wait_until="domcontentloaded")
                u_el = page.query_selector(f'[name="{username_input["name"]}"]')
                p_el = page.query_selector(f'[name="{password_input["name"]}"]')
                if u_el and p_el:
                    # Test with invalid user
                    u_el.fill("definitely_not_a_real_user_xyzzy")
                    p_el.fill("wrongpassword123")
                    form_el = page.query_selector("form")
                    if form_el:
                        submit_btn = form_el.query_selector(
                            'button[type="submit"], input[type="submit"]'
                        )
                        if submit_btn:
                            submit_btn.click()
                        else:
                            form_el.evaluate("form => form.submit()")
                        page.wait_for_load_state("domcontentloaded")
                        invalid_user_response = page.content()

                    # Test with potentially valid user, wrong password
                    page.goto(form["page_url"], wait_until="domcontentloaded")
                    u_el = page.query_selector(f'[name="{username_input["name"]}"]')
                    p_el = page.query_selector(f'[name="{password_input["name"]}"]')
                    if u_el and p_el:
                        u_el.fill("admin")
                        p_el.fill("wrongpassword123")
                        form_el = page.query_selector("form")
                        if form_el:
                            submit_btn = form_el.query_selector(
                                'button[type="submit"], input[type="submit"]'
                            )
                            if submit_btn:
                                submit_btn.click()
                            else:
                                form_el.evaluate("form => form.submit()")
                            page.wait_for_load_state("domcontentloaded")
                            valid_user_response = page.content()

                            # Compare responses for user enumeration
                            if len(invalid_user_response) != len(valid_user_response):
                                diff = abs(
                                    len(invalid_user_response)
                                    - len(valid_user_response)
                                )
                                if diff > 50:
                                    self._add_finding(
                                        "medium", "auth",
                                        "Possible username enumeration",
                                        "Different responses for valid vs invalid usernames "
                                        "may allow attackers to enumerate valid accounts",
                                        url=form["page_url"],
                                        evidence=f"Response length diff: {diff} bytes",
                                    )

                # Test common credentials
                for username, password in COMMON_CREDENTIALS[:5]:
                    page.goto(form["page_url"], wait_until="domcontentloaded")
                    u_el = page.query_selector(f'[name="{username_input["name"]}"]')
                    p_el = page.query_selector(f'[name="{password_input["name"]}"]')
                    if u_el and p_el:
                        u_el.fill(username)
                        p_el.fill(password)
                        form_el = page.query_selector("form")
                        if form_el:
                            submit_btn = form_el.query_selector(
                                'button[type="submit"], input[type="submit"]'
                            )
                            if submit_btn:
                                submit_btn.click()
                            else:
                                form_el.evaluate("form => form.submit()")
                            page.wait_for_load_state("domcontentloaded")

                            # Check if login succeeded (URL changed, dashboard, etc.)
                            current_url = page.url
                            body = page.content().lower()
                            if (
                                current_url != form["page_url"]
                                and not any(
                                    kw in body
                                    for kw in ["invalid", "error", "incorrect", "failed", "wrong"]
                                )
                            ):
                                self._add_finding(
                                    "critical", "auth",
                                    f"Default credentials: {username}/{password or '(empty)'}",
                                    f"Successfully authenticated with default credentials",
                                    url=form["page_url"],
                                    evidence=f"Username: {username}, Password: {password or '(empty)'}",
                                )
                                return

            except Exception:
                continue

    # ------------------------------------------------------------------
    # CORS misconfiguration
    # ------------------------------------------------------------------
    def _check_cors(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Check for CORS misconfigurations."""
        resp = page.goto(target_url, wait_until="domcontentloaded")
        if not resp:
            return

        acao = resp.headers.get("access-control-allow-origin", "")
        acac = resp.headers.get("access-control-allow-credentials", "")

        if acao == "*":
            if acac.lower() == "true":
                self._add_finding(
                    "critical", "cors",
                    "CORS wildcard with credentials",
                    "Access-Control-Allow-Origin is '*' AND credentials are allowed. "
                    "This is a severe misconfiguration.",
                    url=target_url,
                    evidence=f"ACAO: {acao}, ACAC: {acac}",
                )
            else:
                self._add_finding(
                    "low", "cors",
                    "CORS allows all origins",
                    "Access-Control-Allow-Origin is set to '*'",
                    url=target_url,
                    evidence=f"ACAO: {acao}",
                )

        # Test if origin is reflected
        test_page = context.new_page()
        try:
            test_page.set_extra_http_headers({"Origin": "https://evil.com"})
            resp2 = test_page.goto(target_url, wait_until="domcontentloaded")
            if resp2:
                acao2 = resp2.headers.get("access-control-allow-origin", "")
                if acao2 == "https://evil.com":
                    self._add_finding(
                        "high", "cors",
                        "CORS reflects arbitrary origin",
                        "Server reflects the Origin header in Access-Control-Allow-Origin, "
                        "allowing any website to make authenticated cross-origin requests",
                        url=target_url,
                        evidence=f"Sent Origin: https://evil.com, Received ACAO: {acao2}",
                    )
        except Exception:
            pass
        finally:
            test_page.close()

    # ------------------------------------------------------------------
    # Subdomain takeover hints
    # ------------------------------------------------------------------
    def _check_subdomain_takeover(
        self, page: Page, context: BrowserContext, target_url: str
    ) -> None:
        """Check for signs of potential subdomain takeover."""
        takeover_fingerprints = [
            "There isn't a GitHub Pages site here",
            "NoSuchBucket",
            "No Such Account",
            "You're Almost There",
            "a]]>There's nothing here, yet.",
            "The request could not be satisfied",
            "Fastly error: unknown domain",
            "The feed has not been found",
            "This UserVoice subdomain is currently available",
            "project not found",
            "Unrecognized domain",
            "Sorry, this shop is currently unavailable",
        ]

        resp = page.goto(target_url, wait_until="domcontentloaded")
        if resp:
            content = page.content()
            for fingerprint in takeover_fingerprints:
                if fingerprint in content:
                    self._add_finding(
                        "high", "subdomain_takeover",
                        "Possible subdomain takeover",
                        f"Page contains fingerprint indicative of dangling DNS: '{fingerprint}'",
                        url=target_url,
                        evidence=fingerprint,
                    )
                    break

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    def _add_finding(
        self,
        severity: str,
        category: str,
        title: str,
        description: str,
        url: str = "",
        evidence: str = "",
    ) -> None:
        self.findings.append(
            Finding(
                severity=severity,
                category=category,
                title=title,
                description=description,
                url=url or self._base_url,
                evidence=evidence,
            )
        )

    def _is_same_origin(self, url: str) -> bool:
        parsed_base = urlparse(self._base_url)
        parsed_url = urlparse(url)
        return parsed_base.netloc == parsed_url.netloc

    def _inject_param(self, url: str, param: str, value: str) -> str:
        parsed = urlparse(url)
        sep = "&" if parsed.query else "?"
        return f"{parsed.scheme}://{parsed.netloc}{parsed.path}{sep}{urlencode({param: value})}"

    def _html_escaped(self, text: str) -> str:
        return (
            text.replace("&", "&amp;")
            .replace("<", "&lt;")
            .replace(">", "&gt;")
            .replace('"', "&quot;")
            .replace("'", "&#x27;")
        )

    def _on_console_message(self, msg: Any) -> None:
        if msg.type in ("error", "warning"):
            self._console_errors.append(f"[{msg.type}] {msg.text}")

    def _build_report(self, target_url: str) -> Dict[str, Any]:
        summary = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
        for f in self.findings:
            summary[f.severity] = summary.get(f.severity, 0) + 1

        return {
            "target": target_url,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "summary": summary,
            "total_findings": len(self.findings),
            "findings": [f.to_dict() for f in self.findings],
            "pages_crawled": len(self._crawled_urls),
            "forms_discovered": len(self._forms),
            "console_errors": self._console_errors[:50],
        }
